{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# `LlamaCpp` examples\n",
    "\n",
    "This notebook contains usage examples of the llama-cpp-python support in guidance.\n",
    "The first example is RPG character json generator.\n",
    "The second example takes a jsonformer scheme as input and generate a valid json.\n",
    "The third example uses the chat mode of guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T20:46:56.433152200Z",
     "start_time": "2023-05-24T20:46:55.570187500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ../../../../../models/gpt4-x-vicuna-13B-GGML/gpt4-x-vicuna-13B.ggmlv3.q5_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32001\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 8 (mostly Q5_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size = 8535.27 MB\n",
      "llama_model_load_internal: mem required  = 10583.27 MB (+ 1608.00 MB per state)\n",
      "....................................................................................................\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n"
     ]
    }
   ],
   "source": [
    "import guidance\n",
    "\n",
    "# Create a LlamaCpp instance and pass the settings to it.\n",
    "# note this assumes you have llama-cpp-python>=0.1.55 installed\n",
    "llama = guidance.llms.LlamaCpp(\n",
    "    model = \"../../../../../models/gpt4-x-vicuna-13B-GGML/gpt4-x-vicuna-13B.ggmlv3.q5_0.bin\",\n",
    "    tokenizer=\"ehartford/WizardLM-7B-Uncensored\",\n",
    "    n_gpu_layers=10,\n",
    "    n_threads=12\n",
    ")\n",
    "\n",
    "# Other models would look like this:\n",
    "# model = \"../ggml-v3-models/gpt4-x-vicuna-13B.ggmlv3.q5_1.bin\"\n",
    "# tokenizer = \"TheBloke/gpt4-x-vicuna-13B-HF\"\n",
    "\n",
    "# Or like this:\n",
    "# model = \"../ggml-v3-models/Manticore-13B.ggmlv3.q5_1.bin\"\n",
    "# tokenizer = \"openaccess-ai-collective/manticore-13b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T20:46:57.522736200Z",
     "start_time": "2023-05-24T20:46:57.509223300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-d98ffbef-0a94-4f08-a552-15f2f48a5e3f\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-d98ffbef-0a94-4f08-a552-15f2f48a5e3f\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>The following is a character profile for an RPG game in JSON format.\n",
       "```json\n",
       "{\n",
       "    &quot;id&quot;: &quot;<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{id}}'>e1f491f7-7ab8-4dac-8c20-c92b5e7d883d</span>&quot;,\n",
       "    &quot;description&quot;: &quot;<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{description}}'>A quick and nimble fighter.</span>&quot;,\n",
       "    &quot;name&quot;: &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;name&#x27; temperature=0.7}}'>Raven&quot;,</span>&quot;,\n",
       "    &quot;age&quot;: <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;age&#x27; pattern=&#x27;[0-9]+&#x27; max_tokens=2 stop=&#x27;,&#x27;}}'>26</span>,\n",
       "    &quot;armor&quot;: &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{#select &#x27;armor&#x27;}}leather{{or}}chainmail{{or}}plate{{/select}}'>leather</span>&quot;,\n",
       "    &quot;weapon&quot;: &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{select &#x27;weapon&#x27; options=valid_weapons}}'>sword</span>&quot;,\n",
       "    &quot;class&quot;: &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;class&#x27;}}'>rogue&quot;,</span>&quot;,\n",
       "    &quot;mantra&quot;: &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;mantra&#x27; temperature=0.7}}'>Strike fast, strike hard.&quot;,</span>&quot;,\n",
       "    &quot;strength&quot;: <span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;strength&#x27; pattern=&#x27;[0-9]+&#x27; max_tokens=2 stop=&#x27;,&#x27;}}'>16</span>,\n",
       "    &quot;items&quot;: [<span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#geneach &#x27;items&#x27; num_iterations=5 join=&#x27;, &#x27;}}&quot;{{gen &#x27;this&#x27; temperature=0.7}}&quot;{{/geneach}}'>&quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; temperature=0.7}}'>healing potion&quot;],</span>&quot;, &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; temperature=0.7}}'>skills&quot;:</span>&quot;, &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; temperature=0.7}}'>sneak&quot;,</span>&quot;, &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; temperature=0.7}}'>stealth&quot;,</span>&quot;, &quot;<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;this&#x27; temperature=0.7}}'>traps&quot;,</span>&quot;</span>]\n",
       "}```</pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"d98ffbef-0a94-4f08-a552-15f2f48a5e3f\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1st Example\n",
    "# we can pre-define valid option sets\n",
    "valid_weapons = [\"sword\", \"axe\", \"mace\", \"spear\", \"bow\", \"crossbow\"]\n",
    "\n",
    "# define the prompt\n",
    "character_maker = guidance(\"\"\"The following is a character profile for an RPG game in JSON format.\n",
    "```json\n",
    "{\n",
    "    \"id\": \"{{id}}\",\n",
    "    \"description\": \"{{description}}\",\n",
    "    \"name\": \"{{gen 'name' temperature=0.7}}\",\n",
    "    \"age\": {{gen 'age' pattern='[0-9]+' max_tokens=2 stop=','}},\n",
    "    \"armor\": \"{{#select 'armor'}}leather{{or}}chainmail{{or}}plate{{/select}}\",\n",
    "    \"weapon\": \"{{select 'weapon' options=valid_weapons}}\",\n",
    "    \"class\": \"{{gen 'class'}}\",\n",
    "    \"mantra\": \"{{gen 'mantra' temperature=0.7}}\",\n",
    "    \"strength\": {{gen 'strength' pattern='[0-9]+' max_tokens=2 stop=','}},\n",
    "    \"items\": [{{#geneach 'items' num_iterations=5 join=', '}}\"{{gen 'this' temperature=0.7}}\"{{/geneach}}]\n",
    "}```\"\"\")\n",
    "\n",
    "# generate a character\n",
    "char = character_maker(\n",
    "    id=\"e1f491f7-7ab8-4dac-8c20-c92b5e7d883d\",\n",
    "    description=\"A quick and nimble fighter.\",\n",
    "    valid_weapons=valid_weapons, llm=llama, caching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2nd Example\n",
    "# define a recursive function that takes a jsonformer schema and returns a guidance program\n",
    "def jsonformer2guidance(schema, key=None, indent=0):\n",
    "    out = \"\"\n",
    "    if schema['type'] == 'object':\n",
    "        out += \"  \"*indent + \"{\\n\"\n",
    "        for k,v in schema['properties'].items():\n",
    "            out += \"  \"*(indent+1) + k + \": \" + jsonformer2guidance(v, k, indent+1) + \",\\n\"\n",
    "        out += \"  \"*indent + \"}\"\n",
    "        return out\n",
    "    elif schema['type'] == 'array':\n",
    "        if 'max_items' in schema:\n",
    "            extra_args = f\" max_iterations={schema['max_items']}\"\n",
    "        else:\n",
    "            extra_args = \"\"\n",
    "        return \"[{{#geneach '\"+key+\"' stop=']'\"+extra_args+\"}}{{#unless @first}}, {{/unless}}\" + jsonformer2guidance(schema['items'], \"this\") + \"{{/geneach}}]\"\n",
    "    elif schema['type'] == 'string':\n",
    "        return \"\\\"{{gen '\"+key+\"' stop='\\\"'}}\\\"\"\n",
    "    elif schema['type'] == 'number':\n",
    "        return \"{{gen '\"+key+\"' pattern='[0-9\\\\.]' stop=','}}\"\n",
    "    elif schema['type'] == 'boolean':\n",
    "        return \"{{#select '\"+key+\"'}}True{{or}}False{{/select}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a jsonformer schema\n",
    "json_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"number\"},\n",
    "        \"is_student\": {\"type\": \"boolean\"},\n",
    "        \"courses\": {\n",
    "            \"type\": \"array\",\n",
    "            \"max_items\": 6,\n",
    "            \"items\": {\"type\": \"string\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a person's information based on the following schema:\n",
      "{\n",
      "  name: \"John Doe\",\n",
      "  age: 3,\n",
      "  is_student: True,\n",
      "  courses: [\"Math\", \"Science\", \"English\"],\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# run the guidance program\n",
    "prompt = \"Generate a person's information based on the following schema:\"\n",
    "program = guidance(prompt + \"\\n\" + jsonformer2guidance(json_schema))\n",
    "out = program(llm=llama, silent=True)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'tokenizer_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 3rd Example\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# settings =  guidance.llms.LlamaCppSettings()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# settings.model = \"../ggml-v3-models/Manticore-13B-Chat-Pyg.ggmlv3.q5_1.bin\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# settings.before_role = \"<|\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# settings.after_role = \"|>\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m llama \u001b[39m=\u001b[39m guidance\u001b[39m.\u001b[39;49mllms\u001b[39m.\u001b[39;49mLlamaCpp(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     model \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../ggml-v3-models/Manticore-13B-Chat-Pyg.ggmlv3.q5_1.bin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     n_gpu_layers \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     n_threads \u001b[39m=\u001b[39;49m \u001b[39m12\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     tokenizer_name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mopenaccess-ai-collective/manticore-13b-chat-pyg\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     before_role \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m<|\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     after_role \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m|>\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     caching\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, silent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox364.redmond.corp.microsoft.com/home/sclundbe/projects/guidance/notebooks/api_examples/llms/LamaCpp.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'tokenizer_name'"
     ]
    }
   ],
   "source": [
    "# 3rd Example\n",
    "# settings =  guidance.llms.LlamaCppSettings()\n",
    "# settings.model = \"../ggml-v3-models/Manticore-13B-Chat-Pyg.ggmlv3.q5_1.bin\"\n",
    "# settings.n_gpu_layers = 10\n",
    "# settings.n_threads = 12\n",
    "# settings.tokenizer_name = \"openaccess-ai-collective/manticore-13b-chat-pyg\"\n",
    "# settings.before_role = \"<|\"\n",
    "# settings.after_role = \"|>\"\n",
    "llama = guidance.llms.LlamaCpp(\n",
    "    model = \"../ggml-v3-models/Manticore-13B-Chat-Pyg.ggmlv3.q5_1.bin\",\n",
    "    n_gpu_layers = 10,\n",
    "    n_threads = 12,\n",
    "    tokenizer = \"openaccess-ai-collective/manticore-13b-chat-pyg\",\n",
    "    before_role = \"<|\",\n",
    "    after_role = \"|>\",\n",
    "    caching=False, silent=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# llama = guidance.llms.LlamaCpp(settings=settings, caching=False)\n",
    "experts = guidance('''\n",
    "{{#system~}}\n",
    "You are a helpful and terse assistant.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "I want a response to the following question:\n",
    "{{query}}\n",
    "Name 3 world-class experts (past or present) who would be great at answering this?\n",
    "Don't answer the question yet.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'expert_names' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Great, now please answer the question as if these experts had collaborated in writing a joint anonymous answer.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'answer' temperature=0 max_tokens=500}}\n",
    "{{~/assistant}}\n",
    "''', llm=llama)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(experts(query='How can I be more productive?', llm=llama))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
